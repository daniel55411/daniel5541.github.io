Список поставленных задач:
- [ ] Рассмотреть три варианта сипользования Kafka + Akka 
  - [ ] Kafka + Akka как потребитель данных.
  - [x] Kafka + Akka как производиьель данных.
  - [x] Kafka + Akka как flow, трансформация данных.
- [ ] Рассмотреть, как себя ведет Kafka + Akka в следующих случаях:
  - [ ] Неравномерное поступление данных (Например, после маленького сообщения может прийти большое).
  - [ ] Проблема конвесрии данных.
  - [ ] Kafka нагружена.
  - [ ] Нагружен внешний получатель данных.
- [ ] Вычитывать большие объемы данных с помощью разных десериализаторов.
- [ ] Обработка из нескольких партишинов + 2 консамера.
- [ ] Добавить различные форматы ( + тесты, например ключ=значение).
- [ ] Вычитывание данных различным способ:
  - [ ] Kafka -> сырые -> akka -> deserialization -> processing.
  - [ ] Kafka -> deserialization-> akka -> processing.
- [ ] Приоритезация трафика в akka (по HTTP). Например, в заголовках хранить API-key и получение приоритета строится по цепочке API-key -> запрос в хранилище -> получение приоритета.
- [ ] Выборочная остановка ( контролируемый back-pressure)
- [ ] Случай: Kafka отдает быстро - Потребитель работает медленно. По каждому результату необходимы: источник и вывод.
- [x] Как работать с Zookeeper?
  - [x] Хранение метаданных, настроек (авторизации, сервиса, ..).
  - [x] Получение обновлений?
  - [x] Как обновлять настройки?
